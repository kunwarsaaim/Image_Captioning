{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kunwarsaaim/Image_Captioning/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6t5Pt75hcmHr",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cSJ-mmyZh8vo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72accaa0-24a3-4f6f-fa64-464437e580c5"
      },
      "source": [
        "from os import listdir\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.optimizers import Adam\n",
        "import cv2\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XNtVIdu4hCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "a5869cf8-177a-48fd-e97f-1496cfec506e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"content\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOL1dUxj5GeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/content/My Drive/Datasets/Flickr_8k\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JHs2UL2Xij58",
        "colab": {}
      },
      "source": [
        "def load_photos(directory,keys):      #directory:in which photos are stored\n",
        "  image_arr = []\n",
        "  for i in range(10):\n",
        "    filename = directory + '/' + keys[i]+ '.jpg'\n",
        "    #load image from file\n",
        "    image = load_img(filename,target_size=(224,224))\n",
        "   # image =  cv2.imread(filename)\n",
        "    #image = cv2.resize(image,(224,224))\n",
        "    #convert to numpy array\n",
        "    image = img_to_array(image)\n",
        "    #reshape data for the model\n",
        "    image = preprocess_input(image)\n",
        "    #apppend image to images array\n",
        "    image_arr.append(image)\n",
        "  image_arr = np.asarray(image_arr)\n",
        "  return image_arr\n",
        "                          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qmho0OtYmyqS",
        "colab": {}
      },
      "source": [
        "def load_doc(filename):\n",
        "  #open file\n",
        "  file = open(filename,'r')\n",
        "  text = file.read()\n",
        "  file.close()\n",
        "  return text\n",
        "\n",
        "\n",
        "#discription for images\n",
        "def load_discription(doc):\n",
        "  mapping = dict()\n",
        "  for line in doc.split(\"\\n\"):\n",
        "    #split line by white spaces\n",
        "    tokens = line.split()\n",
        "    if len(line)<2:\n",
        "      continue\n",
        "    #first token as image id and rest as caption\n",
        "    image_id,caption = tokens[0],tokens[1:]\n",
        "    #remove filename from image\n",
        "    image_id = image_id.split('.')[0]\n",
        "    #tokens to string\n",
        "    caption = \" \".join(caption)\n",
        "    #store first caption\n",
        "    if image_id not in mapping:\n",
        "      mapping[image_id] = caption\n",
        "  return mapping\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcoq39Fd1U4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_prepross(filename):\n",
        "    #load text from file\n",
        "    raw_text = load_doc(filename)\n",
        "    #seprate caption and image name\n",
        "    text_dict = load_discription(raw_text)\n",
        "    #convert dict to dataframe\n",
        "    text_df = pd.DataFrame(list(text_dict.items()))\n",
        "    #convert text to integers\n",
        "    keys = text_df[0].values\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(text_df[1])\n",
        "    vocab_size = len(tokenizer.word_index)+1\n",
        "    seq = tokenizer.texts_to_sequences(text_df[1])\n",
        "    #make all the tokenized caption of equal length\n",
        "    padded_seq = (sequence.pad_sequences(seq))\n",
        "   # text = tokenizer.sequences_to_texts(padded_seq[0])\n",
        "    #make 2d array to list to assign to dataframe col\n",
        "    #padded_seq = padded_seq.tolist()\n",
        "#     for i in range(len(padded_seq)):\n",
        "#         padded_seq[i] = np.array(padded_seq[i])\n",
        "#         padded_seq[i] = padded_seq[i].reshape(1,33)\n",
        " #   text_df[2] = padded_seq\n",
        "    return padded_seq,vocab_size,tokenizer,keys\n",
        "    \n",
        "#     b = tokenizer.sequences_to_texts([padded_seq[0]]) to covert seq to text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UeIs0bj1U4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"Flickr_TextData/Flickr8k.token.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw9aGV-U1U4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded_seq,vocab,tokenizer,keys = text_prepross(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OSVCixjN_Dg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_arr = load_photos(\"Images\",keys)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaSR7iOz1U5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_arc(vocab_size=4421,learning_rate=0.00051,lstm_layers=3,embedding_size=300,dropout_rate=0.22):\n",
        "    image_input = Input(shape=(224,224,3))\n",
        "    model_vgg16 = VGG16(weights='imagenet',input_tensor=image_input)\n",
        "    for layer in model_vgg16.layers:\n",
        "        layer.trainable = False\n",
        "    dense_input = BatchNormalization(axis=-1)(model_vgg16.layers[-2].output)\n",
        "    image_dense = Dense(units=embedding_size)(dense_input)\n",
        "    image_embedding = RepeatVector(1)(image_dense)\n",
        "    sentence_input = Input(shape=(1,33,))\n",
        "    word_embedding = Embedding(input_dim=vocab_size,output_dim=embedding_size)(sentence_input)\n",
        "    sequence_input = Concatenate(axis=1)([image_embedding,word_embedding])\n",
        "    input_ = sequence_input\n",
        "    for _ in range(lstm_layers):\n",
        "        input_ = BatchNormalization(axis=1)(input_)\n",
        "        lstm_out = LSTM(units=embedding_size,\n",
        "                       return_sequences=True,\n",
        "                       dropout=dropout_rate,\n",
        "                       recurrent_dropout=dropout_rate)(input_)\n",
        "        input_ = lstm_out\n",
        "    sequence_output = TimeDistributed(Dense(units=vocab_size))(lstm_out)\n",
        "    \n",
        "    model = Model(inputs=[image_input,sentence_input],outputs=sequence_output)\n",
        "    model.compile(optimizer=Adam(lr=learning_rate),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "    return model\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGiQyUfF1U5a",
        "colab_type": "code",
        "colab": {},
        "outputId": "f3782e51-cc14-499b-a4cf-9650cf9d16a3"
      },
      "source": [
        "model_arc()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 25088)        0           block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "fc1 (Dense)                     (None, 4096)         102764544   flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 4096)         16384       fc2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 300)          1229100     batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 33)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_2 (RepeatVector)  (None, 1, 300)       0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 33, 300)      1326300     input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 34, 300)      0           repeat_vector_2[0][0]            \n",
            "                                                                 embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 34, 300)      136         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 34, 300)      721200      batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 34, 300)      136         lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 34, 300)      721200      batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 34, 300)      136         lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 34, 300)      721200      batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 34, 4421)     1330721     lstm_3[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 140,327,057\n",
            "Trainable params: 6,058,117\n",
            "Non-trainable params: 134,268,940\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.training.Model at 0xb32bcc3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bXQOgxE1U5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}