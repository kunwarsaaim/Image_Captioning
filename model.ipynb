{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kunwarsaaim/Image_Captioning/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6t5Pt75hcmHr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cSJ-mmyZh8vo"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JHs2UL2Xij58"
   },
   "outputs": [],
   "source": [
    "def load_photos(directory):      #directory:in which photos are stored\n",
    "  features = dict()\n",
    "  in_layer = Input(shape=(224,224,3))\n",
    "  model = VGG16(weights='imagenet',input_tensor=in_layer)\n",
    "  model_new = Model(model.input,model.layers[-2].output)\n",
    "  print(model_new.summary)\n",
    "  for file in listdir(directory):\n",
    "    filename = directort + '/' + file\n",
    "    #load image from file\n",
    "    image = load_img(filename,target_size=(224,224))\n",
    "    #convert to numpy array\n",
    "    image = img_to_array(image)\n",
    "    #reshape data for the model\n",
    "    image = np.expand_dims(image,axis=0)\n",
    "    image = preprocess_input(image)\n",
    "    feature = new_model.predict(image,verbose=0)\n",
    "    #get image id\n",
    "    image_id = file.split(\".\")[0]\n",
    "    #mapping image_id to numpy array converted image\n",
    "    features[image_id] = feature\n",
    "  return features\n",
    "\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qmho0OtYmyqS"
   },
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "  #open file\n",
    "  file = open(filename,'r')\n",
    "  text = file.read()\n",
    "  file.close()\n",
    "  return text\n",
    "\n",
    "\n",
    "#discription for images\n",
    "def load_discription(doc):\n",
    "  mapping = dict()\n",
    "  for line in doc.split(\"\\n\"):\n",
    "    #split line by white spaces\n",
    "    tokens = line.split()\n",
    "    if len(line)<2:\n",
    "      continue\n",
    "    #first token as image id and rest as caption\n",
    "    image_id,caption = tokens[0],tokens[1:]\n",
    "    #remove filename from image\n",
    "    image_id = image_id.split('.')[0]\n",
    "    #tokens to string\n",
    "    caption = \" \".join(caption)\n",
    "    #store first caption\n",
    "    if image_id not in mapping:\n",
    "      mapping[image_id] = caption\n",
    "  return mapping\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prepross(filename):\n",
    "    #load text from file\n",
    "    raw_text = load_doc(filename)\n",
    "    #seprate caption and image name\n",
    "    text_dict = load_discription(raw_text)\n",
    "    #convert dict to dataframe\n",
    "    text_df = pd.DataFrame(list(text_dict.items()))\n",
    "    #convert text to integers\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(text_df[1])\n",
    "    seq = tokenizer.texts_to_sequences(text_df[1])\n",
    "    #make all the tokenized caption of equal length\n",
    "    maxlen = 40\n",
    "    padded_seq = sequence.pad_sequences(seq,maxlen=maxlen)\n",
    "    #make 2d array to list to assign to dataframe col\n",
    "    padded_seq = padded_seq.tolist()\n",
    "    text_df[2] = padded_seq\n",
    "    return text_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Flickr_TextData/Flickr8k.token.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = text_prepross(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000268201_693b08cb0e</td>\n",
       "      <td>A child in a pink dress is climbing up a set o...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001773457_577c3a7d70</td>\n",
       "      <td>A black dog and a spotted dog are fighting</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002674143_1b742ab4b8</td>\n",
       "      <td>A little girl covered in paint sits in front o...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003163366_44323f5815</td>\n",
       "      <td>A man lays on a bench while his dog sits by him .</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1007129816_e794419615</td>\n",
       "      <td>A man in an orange hat starring at something .</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0                                                  1  \\\n",
       "0  1000268201_693b08cb0e  A child in a pink dress is climbing up a set o...   \n",
       "1  1001773457_577c3a7d70         A black dog and a spotted dog are fighting   \n",
       "2  1002674143_1b742ab4b8  A little girl covered in paint sits in front o...   \n",
       "3  1003163366_44323f5815  A man lays on a bench while his dog sits by him .   \n",
       "4  1007129816_e794419615     A man in an orange hat starring at something .   \n",
       "\n",
       "                                                   2  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
