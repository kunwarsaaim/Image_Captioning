{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kunwarsaaim/Image_Captioning/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6t5Pt75hcmHr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cSJ-mmyZh8vo"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JHs2UL2Xij58"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'directory'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5d03f4f0e916>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mimage_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mimage_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mload_photos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"directory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5d03f4f0e916>\u001b[0m in \u001b[0;36mload_photos\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_photos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m      \u001b[0;31m#directory:in which photos are stored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mimage_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectort\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#load image from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'directory'"
     ]
    }
   ],
   "source": [
    "def load_photos(directory):      #directory:in which photos are stored\n",
    "  image_arr = dict()\n",
    "  for file in listdir(directory):\n",
    "    filename = directort + '/' + file\n",
    "    #load image from file\n",
    "    image = load_img(filename,target_size=(224,224))\n",
    "    #convert to numpy array\n",
    "    image = img_to_array(image)\n",
    "    #reshape data for the model\n",
    "    image = np.expand_dims(image,axis=0)\n",
    "    image = preprocess_input(image)\n",
    "    #get image id\n",
    "    image_id = file.split(\".\")[0]\n",
    "    #mapping image_id to numpy array converted image\n",
    "    image_arr[image_id] = image\n",
    "  return image_arr\n",
    "load_photos(\"directory\")\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qmho0OtYmyqS"
   },
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "  #open file\n",
    "  file = open(filename,'r')\n",
    "  text = file.read()\n",
    "  file.close()\n",
    "  return text\n",
    "\n",
    "\n",
    "#discription for images\n",
    "def load_discription(doc):\n",
    "  mapping = dict()\n",
    "  for line in doc.split(\"\\n\"):\n",
    "    #split line by white spaces\n",
    "    tokens = line.split()\n",
    "    if len(line)<2:\n",
    "      continue\n",
    "    #first token as image id and rest as caption\n",
    "    image_id,caption = tokens[0],tokens[1:]\n",
    "    #remove filename from image\n",
    "    image_id = image_id.split('.')[0]\n",
    "    #tokens to string\n",
    "    caption = \" \".join(caption)\n",
    "    #store first caption\n",
    "    if image_id not in mapping:\n",
    "      mapping[image_id] = caption\n",
    "  return mapping\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prepross(filename):\n",
    "    #load text from file\n",
    "    raw_text = load_doc(filename)\n",
    "    #seprate caption and image name\n",
    "    text_dict = load_discription(raw_text)\n",
    "    #convert dict to dataframe\n",
    "    text_df = pd.DataFrame(list(text_dict.items()))\n",
    "    #convert text to integers\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(text_df[1])\n",
    "    vocab_size = len(tokenizer.word_index)+1\n",
    "    seq = tokenizer.texts_to_sequences(text_df[1])\n",
    "    #make all the tokenized caption of equal length\n",
    "    maxlen = 40\n",
    "    padded_seq = sequence.pad_sequences(seq,maxlen=maxlen)\n",
    "    #make 2d array to list to assign to dataframe col\n",
    "    padded_seq = padded_seq.tolist()\n",
    "    text_df[2] = padded_seq\n",
    "    return text_df,vocab_size\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Flickr_TextData/Flickr8k.token.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4421\n"
     ]
    }
   ],
   "source": [
    "df = text_prepross(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000268201_693b08cb0e</td>\n",
       "      <td>A child in a pink dress is climbing up a set o...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001773457_577c3a7d70</td>\n",
       "      <td>A black dog and a spotted dog are fighting</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002674143_1b742ab4b8</td>\n",
       "      <td>A little girl covered in paint sits in front o...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003163366_44323f5815</td>\n",
       "      <td>A man lays on a bench while his dog sits by him .</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1007129816_e794419615</td>\n",
       "      <td>A man in an orange hat starring at something .</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0                                                  1  \\\n",
       "0  1000268201_693b08cb0e  A child in a pink dress is climbing up a set o...   \n",
       "1  1001773457_577c3a7d70         A black dog and a spotted dog are fighting   \n",
       "2  1002674143_1b742ab4b8  A little girl covered in paint sits in front o...   \n",
       "3  1003163366_44323f5815  A man lays on a bench while his dog sits by him .   \n",
       "4  1007129816_e794419615     A man in an orange hat starring at something .   \n",
       "\n",
       "                                                   2  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_arc(image_input,sentence_input,vocab_size,learning_rate,lstm_layers,embedding_size=300,dropout_rate=0.22):\n",
    "    image_input = Input(shape=(224,224,3))\n",
    "    model_vgg16 = VGG16(weights='imagenet',input_tensor=in_layer)\n",
    "    for layer in model_vgg16.layers:\n",
    "        layer.trainable = False\n",
    "    dense_input = BatchNormalization(axis=-1)(model_vgg16.layers[-2].output)\n",
    "    image_dense = Dense(units=embedding_size)(dense_input)\n",
    "    image_embedding = RepeatVector(1)(image_dense)\n",
    "    sentence_input = Input(shape=[None])\n",
    "    word_embedding = Embedding(input_dim=vocab_size,output_dim=embedding_size)(sentence_input)\n",
    "    sequence_input = Concatenate(axis=1)([image_embedding,word_embedding])\n",
    "    input_ = sentence_input\n",
    "    for _ in range(lstm_layers):\n",
    "        input_ = BatchNormalization(axis=1)(input_)\n",
    "        lstm_out = LSTM(units=embedding_size,\n",
    "                       return_sequences=True,\n",
    "                       dropout=dropout_rate,\n",
    "                       recurrent_dropout=dropout_rate)(input_)\n",
    "        input_ = lstm_out\n",
    "    sequence_output = TimeDistributed(Dense(units=vocab_size))(lstm_out)\n",
    "    \n",
    "    model = Model(inputs=[image_input,sentence_input],outputs=sequence_output)\n",
    "    model.compile(optimizer=Adam(lr=learning_rate),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
